{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19o65K4DiQ_k",
        "outputId": "a54688a8-ab53-4c6a-ba52-ad239bd79c05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ijok-hcJEO6m"
      },
      "outputs": [],
      "source": [
        "pip install scikeras\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gXWYLNzKStQp"
      },
      "outputs": [],
      "source": [
        "pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cIszQj3yj4hZ"
      },
      "outputs": [],
      "source": [
        "import matplotlib as mpl\n",
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import plotly.graph_objects as go\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import zipfile\n",
        "from datetime import timedelta\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dropout, RepeatVector, TimeDistributed, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.layers import GRU\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "import optuna\n",
        "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
        "from sklearn.metrics import f1_score, roc_auc_score, precision_score, recall_score\n",
        "from keras.callbacks import Callback\n",
        "from keras.regularizers import L2\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EDcRjIkcYkJS"
      },
      "outputs": [],
      "source": [
        "tromso_4135 = pd.read_csv('/content/drive/MyDrive/finaltromso.csv')\n",
        "oslo_4144 =  pd.read_csv('/content/drive/MyDrive/finaloslo4144.csv')\n",
        "oslo_4147 = pd.read_csv('/content/drive/MyDrive/finaloslo4147.csv')\n",
        "gelio_4137 = pd.read_csv('/content/drive/MyDrive/finalgelio.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trondheim = pd.read_csv('/content/drive/MyDrive/7065.csv')"
      ],
      "metadata": {
        "id": "-R9_Nynw7pbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bergen_4126 = pd.read_csv('/content/drive/MyDrive/4126.csv')"
      ],
      "metadata": {
        "id": "FkqjVzsW-UYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bud_4152 = pd.read_csv('/content/drive/MyDrive/bud_4152_ready.csv')"
      ],
      "metadata": {
        "id": "GWtcsOmcT5Kk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AqZw6RiGY6zG"
      },
      "outputs": [],
      "source": [
        "def label_anomalies(df, rtt_column, threshold):\n",
        "    # Create a new column 'anomaly_label' where each value is 1 if the RTT is greater than the threshold, 0 otherwise\n",
        "    df['anomaly_label'] = (df[rtt_column] > threshold).astype(int)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def engineer_features(df, timestamp):\n",
        "    # Create 'day_of_week' column with categorical day names\n",
        "    df['day_of_week'] = df[timestamp].dt.day_name()\n",
        "\n",
        "    # One-hot encode 'day_of_week' column\n",
        "    df = pd.get_dummies(df, columns=['day_of_week'])\n",
        "\n",
        "    # Drop the 'node_id' column\n",
        "    df.drop('node_id', axis=1, inplace=True)\n",
        "\n",
        "\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "Af1QTDLJvfoY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "onoNnFHTFNeV"
      },
      "outputs": [],
      "source": [
        "def preprocess_and_subset(data, timestamp_col='ts', value_col='rtt', anomaly_threshold=0.05, start_date='2023-11-01 00:00:00', end_date='2023-11-14 23:59:59'):\n",
        "\n",
        "    # Assuming label_anomalies is a function you've defined elsewhere that labels anomalies\n",
        "    processed_data = label_anomalies(data, value_col, anomaly_threshold)\n",
        "\n",
        "    # Convert timestamp column to datetime\n",
        "    processed_data[timestamp_col] = pd.to_datetime(processed_data[timestamp_col])\n",
        "\n",
        "    # Floor the timestamps to the nearest second\n",
        "    processed_data[timestamp_col] = processed_data[timestamp_col].dt.floor(freq=\"s\")\n",
        "\n",
        "    processed_data = engineer_features(data, timestamp_col)\n",
        "\n",
        "    # Set the timestamp column as the index\n",
        "    processed_data = processed_data.set_index(timestamp_col)\n",
        "\n",
        "\n",
        "\n",
        "    # Select and return the subset of data based on the specified date range\n",
        "    subset = processed_data[start_date:end_date]\n",
        "    return subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1PhZSKRvaIjy"
      },
      "outputs": [],
      "source": [
        "gelio_subset = preprocess_and_subset(gelio_4137, 'ts', 'rtt', 0.045, '2023-11-01 00:00:00', '2023-12-31 23:59:59')\n",
        "tromso_subset = preprocess_and_subset(tromso_4135, 'ts', 'rtt', 0.045, '2023-11-01 00:00:00', '2023-12-31 23:59:59')\n",
        "oslo4144_subset = preprocess_and_subset(oslo_4147, 'ts', 'rtt', 0.045, '2023-11-01 00:00:00', '2023-12-31 23:59:59')\n",
        "oslo4147_subset = preprocess_and_subset(oslo_4144, 'ts', 'rtt', 0.045, '2023-11-01 00:00:00', '2023-12-31 23:59:59')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bergen_subset = preprocess_and_subset(bergen_4126, 'ts', 'rtt', 0.045, '2023-11-01 00:00:00', '2023-12-31 23:59:59')"
      ],
      "metadata": {
        "id": "qLLscBJC76ol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trond_subset = preprocess_and_subset(trondheim, 'ts', 'rtt', 0.045, '2023-11-01 00:00:00', '2023-12-31 23:59:59')"
      ],
      "metadata": {
        "id": "MHh1CcS8-o6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bud_subset = preprocess_and_subset(bud_4152, 'ts', 'rtt', 0.045, '2023-11-01 00:00:00', '2023-12-31 23:59:59')"
      ],
      "metadata": {
        "id": "KR3UYjUTWMnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bud_subset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 822
        },
        "id": "EGYF7HM0U5s-",
        "outputId": "58919cfd-8d30-4c1b-b45e-79bb1bfc0e93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          rtt  event_rssi  event_rsrp  event_rsrq  event_band  \\\n",
              "ts                                                                              \n",
              "2023-11-01 00:00:00  0.051132       -80.0      -112.0       -12.0         3.0   \n",
              "2023-11-01 00:00:01  0.050266       -80.0      -111.0       -12.0         3.0   \n",
              "2023-11-01 00:00:02  0.048981       -80.0      -111.0       -12.0         3.0   \n",
              "2023-11-01 00:00:03  0.047081       -80.0      -111.0       -12.0         3.0   \n",
              "2023-11-01 00:00:04  0.047388       -80.0      -111.0       -12.0         3.0   \n",
              "...                       ...         ...         ...         ...         ...   \n",
              "2023-12-31 23:59:55  0.052416       -71.0      -104.0       -15.0        20.0   \n",
              "2023-12-31 23:59:56  0.051409       -71.0      -104.0       -15.0        20.0   \n",
              "2023-12-31 23:59:57  0.052315       -71.0      -104.0       -16.0        20.0   \n",
              "2023-12-31 23:59:58  0.051305       -71.0      -104.0       -15.0        20.0   \n",
              "2023-12-31 23:59:59  0.050255       -71.0      -104.0       -15.0        20.0   \n",
              "\n",
              "                     event_device_state  event_lte_freq  anomaly_label  \\\n",
              "ts                                                                       \n",
              "2023-11-01 00:00:00                 3.0          1800.0              1   \n",
              "2023-11-01 00:00:01                 3.0          1800.0              1   \n",
              "2023-11-01 00:00:02                 3.0          1800.0              1   \n",
              "2023-11-01 00:00:03                 3.0          1800.0              1   \n",
              "2023-11-01 00:00:04                 3.0          1800.0              1   \n",
              "...                                 ...             ...            ...   \n",
              "2023-12-31 23:59:55                 3.0           800.0              1   \n",
              "2023-12-31 23:59:56                 3.0           800.0              1   \n",
              "2023-12-31 23:59:57                 3.0           800.0              1   \n",
              "2023-12-31 23:59:58                 3.0           800.0              1   \n",
              "2023-12-31 23:59:59                 3.0           800.0              1   \n",
              "\n",
              "                     day_of_week_Friday  day_of_week_Monday  \\\n",
              "ts                                                            \n",
              "2023-11-01 00:00:00               False               False   \n",
              "2023-11-01 00:00:01               False               False   \n",
              "2023-11-01 00:00:02               False               False   \n",
              "2023-11-01 00:00:03               False               False   \n",
              "2023-11-01 00:00:04               False               False   \n",
              "...                                 ...                 ...   \n",
              "2023-12-31 23:59:55               False               False   \n",
              "2023-12-31 23:59:56               False               False   \n",
              "2023-12-31 23:59:57               False               False   \n",
              "2023-12-31 23:59:58               False               False   \n",
              "2023-12-31 23:59:59               False               False   \n",
              "\n",
              "                     day_of_week_Saturday  day_of_week_Sunday  \\\n",
              "ts                                                              \n",
              "2023-11-01 00:00:00                 False               False   \n",
              "2023-11-01 00:00:01                 False               False   \n",
              "2023-11-01 00:00:02                 False               False   \n",
              "2023-11-01 00:00:03                 False               False   \n",
              "2023-11-01 00:00:04                 False               False   \n",
              "...                                   ...                 ...   \n",
              "2023-12-31 23:59:55                 False                True   \n",
              "2023-12-31 23:59:56                 False                True   \n",
              "2023-12-31 23:59:57                 False                True   \n",
              "2023-12-31 23:59:58                 False                True   \n",
              "2023-12-31 23:59:59                 False                True   \n",
              "\n",
              "                     day_of_week_Thursday  day_of_week_Tuesday  \\\n",
              "ts                                                               \n",
              "2023-11-01 00:00:00                 False                False   \n",
              "2023-11-01 00:00:01                 False                False   \n",
              "2023-11-01 00:00:02                 False                False   \n",
              "2023-11-01 00:00:03                 False                False   \n",
              "2023-11-01 00:00:04                 False                False   \n",
              "...                                   ...                  ...   \n",
              "2023-12-31 23:59:55                 False                False   \n",
              "2023-12-31 23:59:56                 False                False   \n",
              "2023-12-31 23:59:57                 False                False   \n",
              "2023-12-31 23:59:58                 False                False   \n",
              "2023-12-31 23:59:59                 False                False   \n",
              "\n",
              "                     day_of_week_Wednesday  \n",
              "ts                                          \n",
              "2023-11-01 00:00:00                   True  \n",
              "2023-11-01 00:00:01                   True  \n",
              "2023-11-01 00:00:02                   True  \n",
              "2023-11-01 00:00:03                   True  \n",
              "2023-11-01 00:00:04                   True  \n",
              "...                                    ...  \n",
              "2023-12-31 23:59:55                  False  \n",
              "2023-12-31 23:59:56                  False  \n",
              "2023-12-31 23:59:57                  False  \n",
              "2023-12-31 23:59:58                  False  \n",
              "2023-12-31 23:59:59                  False  \n",
              "\n",
              "[4969098 rows x 15 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-14835844-2b44-427e-a0f4-8b57f2c30b24\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rtt</th>\n",
              "      <th>event_rssi</th>\n",
              "      <th>event_rsrp</th>\n",
              "      <th>event_rsrq</th>\n",
              "      <th>event_band</th>\n",
              "      <th>event_device_state</th>\n",
              "      <th>event_lte_freq</th>\n",
              "      <th>anomaly_label</th>\n",
              "      <th>day_of_week_Friday</th>\n",
              "      <th>day_of_week_Monday</th>\n",
              "      <th>day_of_week_Saturday</th>\n",
              "      <th>day_of_week_Sunday</th>\n",
              "      <th>day_of_week_Thursday</th>\n",
              "      <th>day_of_week_Tuesday</th>\n",
              "      <th>day_of_week_Wednesday</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ts</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2023-11-01 00:00:00</th>\n",
              "      <td>0.051132</td>\n",
              "      <td>-80.0</td>\n",
              "      <td>-112.0</td>\n",
              "      <td>-12.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1800.0</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-11-01 00:00:01</th>\n",
              "      <td>0.050266</td>\n",
              "      <td>-80.0</td>\n",
              "      <td>-111.0</td>\n",
              "      <td>-12.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1800.0</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-11-01 00:00:02</th>\n",
              "      <td>0.048981</td>\n",
              "      <td>-80.0</td>\n",
              "      <td>-111.0</td>\n",
              "      <td>-12.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1800.0</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-11-01 00:00:03</th>\n",
              "      <td>0.047081</td>\n",
              "      <td>-80.0</td>\n",
              "      <td>-111.0</td>\n",
              "      <td>-12.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1800.0</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-11-01 00:00:04</th>\n",
              "      <td>0.047388</td>\n",
              "      <td>-80.0</td>\n",
              "      <td>-111.0</td>\n",
              "      <td>-12.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1800.0</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-12-31 23:59:55</th>\n",
              "      <td>0.052416</td>\n",
              "      <td>-71.0</td>\n",
              "      <td>-104.0</td>\n",
              "      <td>-15.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-12-31 23:59:56</th>\n",
              "      <td>0.051409</td>\n",
              "      <td>-71.0</td>\n",
              "      <td>-104.0</td>\n",
              "      <td>-15.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-12-31 23:59:57</th>\n",
              "      <td>0.052315</td>\n",
              "      <td>-71.0</td>\n",
              "      <td>-104.0</td>\n",
              "      <td>-16.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-12-31 23:59:58</th>\n",
              "      <td>0.051305</td>\n",
              "      <td>-71.0</td>\n",
              "      <td>-104.0</td>\n",
              "      <td>-15.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-12-31 23:59:59</th>\n",
              "      <td>0.050255</td>\n",
              "      <td>-71.0</td>\n",
              "      <td>-104.0</td>\n",
              "      <td>-15.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4969098 rows × 15 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-14835844-2b44-427e-a0f4-8b57f2c30b24')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-14835844-2b44-427e-a0f4-8b57f2c30b24 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-14835844-2b44-427e-a0f4-8b57f2c30b24');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c9ec564e-e14f-4f2b-9fda-00ece5737e2c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c9ec564e-e14f-4f2b-9fda-00ece5737e2c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c9ec564e-e14f-4f2b-9fda-00ece5737e2c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "bud_subset"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbSA-tXFEsSn"
      },
      "outputs": [],
      "source": [
        "gelio_subset.to_csv(\"/content/drive/MyDrive/gelio_feature_eng.csv\", index=True)\n",
        "tromso_subset.to_csv(\"/content/drive/MyDrive/tromso_feature_eng.csv\", index=True)\n",
        "oslo4147_subset.to_csv(\"/content/drive/MyDrive/oslo4147_feature_eng.csv\", index=True)\n",
        "oslo4144_subset.to_csv(\"/content/drive/MyDrive/oslo4144_feature_eng.csv\", index=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bud_subset.to_csv(\"/content/drive/MyDrive/bud_feature_eng.csv\", index=True)"
      ],
      "metadata": {
        "id": "jdsps1qa8IsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3KtJ0GXiGqw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trond_subset.to_csv(\"/content/drive/MyDrive/trond7065_feature_eng.csv\", index=True)"
      ],
      "metadata": {
        "id": "FVIRv9LxGrny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56yBUQJa2CnW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import f1_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import GRU, Dense, Dropout, LSTM\n",
        "from keras.regularizers import L2\n",
        "from keras.callbacks import EarlyStopping, TensorBoard, Callback\n",
        "import optuna\n",
        "from optuna.visualization import plot_pareto_front, plot_optimization_history, plot_param_importances\n",
        "\n",
        "# Assuming data_subset is loaded here. For example:\n",
        "# data_subset = pd.read_csv('your_data.csv')\n",
        "\n",
        "class F1ScoreCallback(Callback):\n",
        "    def __init__(self, val_data, val_labels):\n",
        "        super().__init__()  # Initialize superclass\n",
        "        self.val_data = val_data\n",
        "        self.val_labels = val_labels\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        val_pred = (self.model.predict(self.val_data) > 0.5).astype(int)\n",
        "        val_f1 = f1_score(self.val_labels, val_pred, average='binary')\n",
        "        print(f'\\nEpoch {epoch + 1}: Validation F1 Score: {val_f1:.4f}')\n",
        "\n",
        "# Assuming create_sequences, split_time_series_data, and preprocessing steps are correct as in your initial script\n",
        "\n",
        "def create_model(model_type, units, dropout_rate, num_layers, l2_rate, input_shape=(100, 14)):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Ensure proper handling of input_shape for all layers and include L2 regularization\n",
        "\n",
        "    if model_type=='GRU':\n",
        "      for layer_num in range(num_layers):\n",
        "          if layer_num == 0:\n",
        "             # For the first layer, specify the input shape\n",
        "             model.add(GRU(units=units, return_sequences=True if num_layers > 1 else False,\n",
        "                          dropout=dropout_rate, kernel_regularizer=L2(l2_rate),\n",
        "                          input_shape=input_shape))\n",
        "          else:\n",
        "             # Subsequent layers do not require the input shape\n",
        "             model.add(GRU(units=units, return_sequences=True if layer_num < num_layers - 1 else False,\n",
        "                          dropout=dropout_rate, kernel_regularizer=L2(l2_rate)))\n",
        "\n",
        "    else:\n",
        "      for layer_num in range(num_layers):\n",
        "          if layer_num == 0:\n",
        "             # For the first layer, specify the input shape\n",
        "             model.add(LSTM(units=units, return_sequences=True if num_layers > 1 else False,\n",
        "                          dropout=dropout_rate, kernel_regularizer=L2(l2_rate),\n",
        "                          input_shape=input_shape))\n",
        "          else:\n",
        "             # Subsequent layers do not require the input shape\n",
        "             model.add(LSTM(units=units, return_sequences=True if layer_num < num_layers - 1 else False,\n",
        "                          dropout=dropout_rate, kernel_regularizer=L2(l2_rate)))\n",
        "\n",
        "    # Add remaining layers after the stacked GRUs\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(units // 2, activation='relu', kernel_regularizer=L2(l2_rate)))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(1, activation='sigmoid', kernel_regularizer=L2(l2_rate)))  # Output layer for binary classification\n",
        "\n",
        "    # Compile the model with the specified optimizer\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def create_sequences(data, time_steps=100, target_column_name='anomaly_label'):\n",
        "    Xs, ys = [], []\n",
        "    for i in range(len(data) - time_steps):\n",
        "        Xs.append(data.iloc[i:(i + time_steps)].drop(columns=[target_column_name]).values)\n",
        "        ys.append(data.iloc[i + time_steps][target_column_name])\n",
        "    return np.array(Xs), np.array(ys)\n",
        "\n",
        "\n",
        "def split_time_series_data(Xs, ys, train_ratio=0.8, val_ratio=0.1):\n",
        "    total_samples = Xs.shape[0]\n",
        "    train_index = int(total_samples * train_ratio)\n",
        "    val_index = train_index + int(total_samples * (val_ratio))\n",
        "\n",
        "    X_train, y_train = Xs[:train_index], ys[:train_index]\n",
        "    X_val, y_val = Xs[train_index:val_index], ys[train_index:val_index]\n",
        "    X_test, y_test = Xs[val_index:], ys[val_index:]\n",
        "\n",
        "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
        "\n",
        "def objective(trial, model_type):\n",
        "    units = trial.suggest_categorical('units', [32, 64, 128])\n",
        "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.3)\n",
        "    num_layers = trial.suggest_int('num_layers', 1, 3)\n",
        "    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])\n",
        "    l2_rate = trial.suggest_float('l2_rate', 1e-5, 1e-2, log=True)\n",
        "\n",
        "    model = create_model(model_type, units, dropout_rate, num_layers, l2_rate)\n",
        "\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
        "    f1_callback = F1ScoreCallback(val_data=X_val_scaled, val_labels=y_val)\n",
        "\n",
        "    model.fit(X_train_scaled, y_train, epochs=10, batch_size=batch_size,\n",
        "              validation_data=(X_val_scaled, y_val), callbacks=[early_stopping, f1_callback])\n",
        "\n",
        "    val_loss, val_accuracy = model.evaluate(X_val_scaled, y_val, verbose=0)\n",
        "    predictions_proba = model.predict(X_val_scaled)\n",
        "    predictions = (predictions_proba > 0.5).astype(int)\n",
        "    val_f1 = f1_score(y_val, predictions, average='binary')\n",
        "\n",
        "    trial.set_user_attr(\"f1_score\", val_f1)\n",
        "    return val_loss, val_f1\n",
        "\n",
        "\n",
        "Xs, ys = create_sequences(oslo4144_subset, 100, 'anomaly_label')\n",
        "\n",
        "X_train, y_train, X_val, y_val, X_test, y_test= split_time_series_data(Xs, ys,train_ratio=0.8, val_ratio=0.2)\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit on training data\n",
        "X_train_scaled = scaler.fit_transform(X_train.reshape(-1, X_train.shape[-1])).reshape(X_train.shape)\n",
        "\n",
        "# Transform validation and test data\n",
        "X_val_scaled = scaler.transform(X_val.reshape(-1, X_val.shape[-1])).reshape(X_val.shape)\n",
        "X_test_scaled = scaler.transform(X_test.reshape(-1, X_test.shape[-1])).reshape(X_test.shape)\n",
        "\n",
        "\n",
        "# Optimize GRU model\n",
        "study_gru = optuna.create_study(directions=['minimize', 'maximize'], study_name=\"GRU_Optimization\")\n",
        "study_gru.optimize(lambda trial: objective(trial, 'GRU'), n_trials=20)\n",
        "\n",
        "# Optimize LSTM model\n",
        "study_lstm = optuna.create_study(directions=['minimize', 'maximize'], study_name=\"LSTM_Optimization\")\n",
        "study_lstm.optimize(lambda trial: objective(trial, 'LSTM'), n_trials=20)\n",
        "\n",
        "# Example of saving and\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Saving Pareto Front for GRU\n",
        "pareto_plot_gru = plot_pareto_front(study_gru, target_names=[\"loss\", \"F1\"])\n",
        "pareto_plot_gru.write_html(\"GRU_Pareto_Front.html\")\n",
        "\n",
        "# Saving Optimization History for GRU\n",
        "optimization_history_gru = plot_optimization_history(study_gru, target_names=[\"loss\", \"F1\"])\n",
        "optimization_history_gru.write_html(\"GRU_Optimization_History.html\")\n",
        "\n",
        "# Saving Parameter Importances for GRU\n",
        "param_importances_gru = plot_param_importances(study_gru, target_names=[\"loss\", \"F1\"])\n",
        "param_importances_gru.write_html(\"GRU_Parameter_Importances.html\")\n",
        "\n",
        "\n",
        "# Saving Pareto Front for LSTM\n",
        "pareto_plot_lstm = plot_pareto_front(study_lstm, target_names=[\"loss\", \"F1\"])\n",
        "pareto_plot_lstm.write_html(\"LSTM_Pareto_Front.html\")\n",
        "\n",
        "# Saving Optimization History for LSTM\n",
        "optimization_history_lstm = plot_optimization_history(study_lstm, target_names=[\"loss\", \"F1\"])\n",
        "optimization_history_lstm.write_html(\"LSTM_Optimization_History.html\")\n",
        "\n",
        "# Saving Parameter Importances for LSTM\n",
        "param_importances_lstm = plot_param_importances(study_lstm, target_names=[\"loss\", \"F1\"])\n",
        "param_importances_lstm.write_html(\"LSTM_Parameter_Importances.html\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yg-XqpdpM8E_"
      },
      "outputs": [],
      "source": [
        "def create_sequences(data, time_steps, target_column_name):\n",
        "    Xs, ys, timestamps = [], [], []\n",
        "    for i in range(len(data) - time_steps):\n",
        "        # Extract features by excluding the target column\n",
        "        Xs.append(data.iloc[i:(i + time_steps)].drop(columns=[target_column_name]).values)\n",
        "\n",
        "        # Extract the target variable using the specified column name\n",
        "        ys.append(data.iloc[i + time_steps][target_column_name])\n",
        "\n",
        "        # Extract the timestamp for each sequence's target value\n",
        "        timestamps.append(data.index[i + time_steps])\n",
        "    return np.array(timestamps), np.array(Xs), np.array(ys)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxAfTyfINB1c"
      },
      "outputs": [],
      "source": [
        "def split_time_series_data(data, Xs, ys, timestamps, train_ratio=0.7, val_ratio=0.1):\n",
        "\n",
        "    total_rows = len(data)\n",
        "    train_index = int(total_rows * train_ratio)\n",
        "    val_index = train_index + int(total_rows * val_ratio)\n",
        "\n",
        "    X_train = Xs[:train_index]\n",
        "    y_train = ys[:train_index]\n",
        "    timestamps_train = timestamps[:train_index]\n",
        "\n",
        "    X_val = Xs[train_index:val_index]\n",
        "    y_val = ys[train_index:val_index]\n",
        "    timestamps_val = timestamps[train_index:val_index]\n",
        "\n",
        "    X_test = Xs[val_index:]\n",
        "    y_test = ys[val_index:]\n",
        "    timestamps_test = timestamps[val_index:]\n",
        "\n",
        "    return (X_train, y_train, timestamps_train,\n",
        "            X_val, y_val, timestamps_val,\n",
        "            X_test, y_test, timestamps_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wa8Sp0BKhD4S"
      },
      "outputs": [],
      "source": [
        "timestamps, Xs, ys = create_sequences(gelio_subset, 100, 'anomaly_label')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nM6MxWgbgyuu"
      },
      "outputs": [],
      "source": [
        "X_train, y_train, timestamps_train, X_val, y_val, timestamps_val, X_test, y_test, timestamps_test = split_time_series_data(gelio_subset, Xs, ys, timestamps, train_ratio=0.7, val_ratio=0.2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "utvnwxKP0PLg"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit on training data\n",
        "X_train_scaled = scaler.fit_transform(X_train.reshape(-1, X_train.shape[-1])).reshape(X_train.shape)\n",
        "\n",
        "# Transform validation and test data\n",
        "X_val_scaled = scaler.transform(X_val.reshape(-1, X_val.shape[-1])).reshape(X_val.shape)\n",
        "X_test_scaled = scaler.transform(X_test.reshape(-1, X_test.shape[-1])).reshape(X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zDwOzgu1FieY"
      },
      "outputs": [],
      "source": [
        "X_train_scaled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aUZzq-ZaauwZ"
      },
      "outputs": [],
      "source": [
        "def create_gru_model(units, dropout_rate, num_layers, l2_rate, input_shape=None, output_size=1, optimizer='adam'):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Ensure proper handling of input_shape for all layers and include L2 regularization\n",
        "    for layer_num in range(num_layers):\n",
        "        if layer_num == 0:\n",
        "            # For the first layer, specify the input shape\n",
        "            model.add(GRU(units=units, return_sequences=True if num_layers > 1 else False,\n",
        "                          dropout=dropout_rate, kernel_regularizer=L2(l2_rate),\n",
        "                          input_shape=input_shape))\n",
        "        else:\n",
        "            # Subsequent layers do not require the input shape\n",
        "            model.add(GRU(units=units, return_sequences=True if layer_num < num_layers - 1 else False,\n",
        "                          dropout=dropout_rate, kernel_regularizer=L2(l2_rate)))\n",
        "\n",
        "    # Add remaining layers after the stacked GRUs\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(units // 2, activation='relu', kernel_regularizer=L2(l2_rate)))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(output_size, activation='sigmoid', kernel_regularizer=L2(l2_rate)))  # Output layer for binary classification\n",
        "\n",
        "    # Compile the model with the specified optimizer\n",
        "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "#model = KerasClassifier(model=create_gru_model, model__input_shape=(100, 8), model__units=64, model__dropout_rate=0.2, model__optimizer='adam', model__output_size=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_LSTM_model(units, dropout_rate, num_layers, input_shape=None, output_size=1, optimizer='adam'):\n",
        "\n",
        "  model = Sequential()\n",
        "\n",
        "  # Ensure proper handling of input_shape for all layers\n",
        "  for _ in range(num_layers):\n",
        "    model.add(LSTM(units=units, return_sequences=True, dropout=dropout_rate,\n",
        "                  input_shape=input_shape if _ == 0 else (None, input_shape[-1])))\n",
        "\n",
        "  # Add remaining layers after the stacked GRUs\n",
        "  model.add(LSTM(units, return_sequences=False))  # Final GRU layer with return_sequences=False\n",
        "  model.add(Dropout(dropout_rate))\n",
        "  model.add(Dense(units // 2, activation='relu'))\n",
        "  model.add(Dropout(dropout_rate))\n",
        "  model.add(Dense(output_size, activation='sigmoid'))  # Output layer for binary classification\n",
        "\n",
        "  model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "N_cY2AOJoIUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_callback = F1ScoreCallback(X_train, y_train, X_val_scaled, y_val)\n"
      ],
      "metadata": {
        "id": "xzzax5pQkgNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b91_95LhS6p1"
      },
      "outputs": [],
      "source": [
        "def objective(trial):\n",
        "  # Define hyperparameters using trial object\n",
        "  units = trial.suggest_categorical('units', [32, 64, 128])\n",
        "  dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.3)\n",
        "  num_layers = trial.suggest_int('num_layers', 1, 3)  # Search for 1 to 3 layers\n",
        "  batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])\n",
        "  l2_rate = trial.suggest_float('l2_rate', 1e-5, 1e-2, log=True)\n",
        "  input_shape = (100, 14)\n",
        "\n",
        "  # Create GRU model with additional layers\n",
        "  model = create_gru_model(units=units, dropout_rate=dropout_rate, num_layers=num_layers,\n",
        "                           input_shape= input_shape, l2_rate=l2_rate)\n",
        "\n",
        "  # Early stopping callback\n",
        "  early_stopping = EarlyStopping(monitor='val_loss', patience=4)\n",
        "\n",
        "\n",
        "  # TensorBoard callback for visualization (optional)\n",
        "  tensorboard = TensorBoard(log_dir='/content/drive/MyDrive/logs', write_graph=True)  # Adjust log directory as needed\n",
        "\n",
        "  # Model fitting with callbacks\n",
        "  history = model.fit(X_train_scaled, y_train, epochs=50, batch_size=batch_size,\n",
        "                      validation_data=(X_val_scaled, y_val),\n",
        "                      callbacks=[early_stopping, f1_callback])\n",
        "\n",
        "  # Evaluation based on test set\n",
        "  test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
        "\n",
        "  # Use predictions on the validation set for F1 score calculation\n",
        "  predictions_proba = model.predict(X_val_scaled)\n",
        "  predictions = (predictions_proba > 0.5).astype(int)\n",
        "\n",
        "  f1 = f1_score(y_val, predictions, average='binary')  # Note: Changed to y_val for consistency with validation phase\n",
        "\n",
        "  # Logging additional metrics for analysis\n",
        "  trial.set_user_attr(\"f1_score\", f1)\n",
        "\n",
        "  # Optimize for test loss, but monitor F1 score\n",
        "  return test_loss, f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VD0-5VbOT3dP"
      },
      "outputs": [],
      "source": [
        "study = optuna.create_study(directions=['minimize', 'maximize'],\n",
        "                            study_name=\"GRU1\")\n",
        "\n",
        "# Optimize the study, the study object is updated in place\n",
        "study.optimize(objective, n_trials=20)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import Callback\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "class F1ScoreCallback(Callback):\n",
        "    def __init__(self, train_data, train_labels, val_data, val_labels):\n",
        "        self.train_data = train_data\n",
        "        self.train_labels = train_labels\n",
        "        self.val_data = val_data\n",
        "        self.val_labels = val_labels\n",
        "        self.val_f1_scores = []  # Optionally store validation F1 scores\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        # Efficient prediction and F1 score computation\n",
        "        val_pred = (self.model.predict(self.val_data) > 0.5).astype(int)\n",
        "        val_f1 = f1_score(self.val_labels, val_pred, average='binary')\n",
        "        self.val_f1_scores.append(val_f1)  # Store if needed\n",
        "        print(f'\\nEpoch {epoch+1}: Validation F1 Score: {val_f1:.4f}')\n"
      ],
      "metadata": {
        "id": "YvuH_dM_ZaKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sDKunbnGkeZu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Set the learning rate\n",
        "learning_rate = 0.001  # Example learning rate\n",
        "\n",
        "# Create the optimizer with the desired learning rate\n",
        "adam_optimizer = Adam(learning_rate=learning_rate)\n",
        "\n",
        "l2_regularizer_rate = 0.001  # This is a hyperparameter you can tune\n",
        "\n",
        "model = Sequential()\n",
        "model.add(GRU(units=128, return_sequences=False, dropout=0.2,\n",
        "              input_shape=(100, 14),\n",
        "              kernel_regularizer=L2(l2_regularizer_rate),  # Apply L2 regularization to the GRU layer\n",
        "              recurrent_regularizer=L2(l2_regularizer_rate)))  # Optional: Apply to recurrent kernel as well\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(128 // 2, activation='relu',\n",
        "                kernel_regularizer=L2(l2_regularizer_rate)))  # Apply L2 regularization to the Dense layer\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation='sigmoid',\n",
        "                kernel_regularizer=L2(l2_regularizer_rate)))  # Apply L2 regularization to the output layer\n",
        "\n",
        "model.compile(optimizer=adam_optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
        "\n",
        "\n",
        "  # TensorBoard callback for visualization (optional)\n",
        "#tensorboard = TensorBoard(log_dir='/content/drive/MyDrive/logs', write_graph=True)  # Adjust log directory as needed\n",
        "\n",
        "history =  model.fit(X_train_scaled, y_train, epochs=50, batch_size=32,\n",
        "                        validation_data=(X_val_scaled, y_val),\n",
        "                        callbacks=[early_stopping, f1_callback])\n",
        "\n",
        "  # Evaluation\n",
        "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
        "\n",
        "  # You can report additional metrics with trial.set_user_attr\n",
        "predictions_proba = model.predict(X_test_scaled)\n",
        "predictions = (predictions_proba > 0.5).astype(int)  # Thresholding to get binary predictions\n",
        "\n",
        "  # Calculate metrics\n",
        "f1 = f1_score(y_test, predictions, average='macro')\n",
        "precision = precision_score(y_test, predictions)\n",
        "recall = recall_score(y_test, predictions)"
      ],
      "metadata": {
        "id": "rTNgmW6i_Nkr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "oslo4144_subset"
      ],
      "metadata": {
        "id": "iigVn-ArC7YO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEzORQBaC_l0",
        "outputId": "cc1f7416-f520-4f5f-cf86-edcff4cd1df1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7514765938776199"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6AEmyfSa0Pxb"
      },
      "outputs": [],
      "source": [
        "best_trial = study.best_trials"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t0pllYJS0VHZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7a71563-b8ff-4a34-f9a5-4dc9570e655f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[FrozenTrial(number=1, state=TrialState.COMPLETE, values=[0.4322155714035034, 0.46587222790442795], datetime_start=datetime.datetime(2024, 3, 17, 20, 48, 54, 10396), datetime_complete=datetime.datetime(2024, 3, 17, 21, 13, 28, 880122), params={'units': 128, 'dropout_rate': 0.2715982395549798, 'num_layers': 1, 'batch_size': 32, 'epochs': 100}, user_attrs={'f1_score': 0.46587222790442795, 'precision': 0.5434782608695652, 'recall': 0.0030120481927710845}, system_attrs={'nsga2:generation': 0}, intermediate_values={}, distributions={'units': CategoricalDistribution(choices=(32, 64, 128)), 'dropout_rate': FloatDistribution(high=0.5, log=False, low=0.2, step=None), 'num_layers': IntDistribution(high=3, log=False, low=1, step=1), 'batch_size': CategoricalDistribution(choices=(32, 64, 128)), 'epochs': CategoricalDistribution(choices=(25, 50, 100, 150))}, trial_id=1, value=None)]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "best_trial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65d16ddme2qM"
      },
      "outputs": [],
      "source": [
        "df = study.trials_dataframe()\n",
        "df.to_csv(\"study_results.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jszp43AxQi6N"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "print(optuna.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-q9IWKcAs7L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "f3c9aaa3-0bab-421c-c1bf-612fa82d9c3a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"1791f6dc-5f08-4b2d-9e65-3b98dffb9e39\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"1791f6dc-5f08-4b2d-9e65-3b98dffb9e39\")) {                    Plotly.newPlot(                        \"1791f6dc-5f08-4b2d-9e65-3b98dffb9e39\",                        [{\"hovertemplate\":\"%{text}\\u003cextra\\u003eTrial\\u003c\\u002fextra\\u003e\",\"marker\":{\"color\":[0,2],\"colorbar\":{\"title\":{\"text\":\"Trial\"}},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"line\":{\"color\":\"Grey\",\"width\":0.5}},\"mode\":\"markers\",\"showlegend\":false,\"text\":[\"{\\u003cbr\\u003e  \\\"number\\\": 0,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    0.4398121237754822,\\u003cbr\\u003e    0.4640770279909556\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"units\\\": 128,\\u003cbr\\u003e    \\\"dropout_rate\\\": 0.26825509787972746,\\u003cbr\\u003e    \\\"num_layers\\\": 3,\\u003cbr\\u003e    \\\"batch_size\\\": 64,\\u003cbr\\u003e    \\\"epochs\\\": 150\\u003cbr\\u003e  },\\u003cbr\\u003e  \\\"user_attrs\\\": {\\u003cbr\\u003e    \\\"f1_score\\\": 0.4640770279909556,\\u003cbr\\u003e    \\\"precision\\\": 0.10204081632653061,\\u003cbr\\u003e    \\\"recall\\\": 0.0018072289156626507\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 2,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    0.8308559060096741,\\u003cbr\\u003e    0.35652518679220324\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"units\\\": 64,\\u003cbr\\u003e    \\\"dropout_rate\\\": 0.4784359638975121,\\u003cbr\\u003e    \\\"num_layers\\\": 3,\\u003cbr\\u003e    \\\"batch_size\\\": 32,\\u003cbr\\u003e    \\\"epochs\\\": 100\\u003cbr\\u003e  },\\u003cbr\\u003e  \\\"user_attrs\\\": {\\u003cbr\\u003e    \\\"f1_score\\\": 0.35652518679220324,\\u003cbr\\u003e    \\\"precision\\\": 0.135052569944757,\\u003cbr\\u003e    \\\"recall\\\": 0.6391566265060241\\u003cbr\\u003e  }\\u003cbr\\u003e}\"],\"x\":[0.4398121237754822,0.8308559060096741],\"y\":[0.4640770279909556,0.35652518679220324],\"type\":\"scatter\"},{\"hovertemplate\":\"%{text}\\u003cextra\\u003eBest Trial\\u003c\\u002fextra\\u003e\",\"marker\":{\"color\":[1],\"colorbar\":{\"title\":{\"text\":\"Best Trial\"},\"x\":1.1,\"xpad\":40},\"colorscale\":[[0.0,\"rgb(255,245,240)\"],[0.125,\"rgb(254,224,210)\"],[0.25,\"rgb(252,187,161)\"],[0.375,\"rgb(252,146,114)\"],[0.5,\"rgb(251,106,74)\"],[0.625,\"rgb(239,59,44)\"],[0.75,\"rgb(203,24,29)\"],[0.875,\"rgb(165,15,21)\"],[1.0,\"rgb(103,0,13)\"]],\"line\":{\"color\":\"Grey\",\"width\":0.5}},\"mode\":\"markers\",\"showlegend\":false,\"text\":[\"{\\u003cbr\\u003e  \\\"number\\\": 1,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    0.4322155714035034,\\u003cbr\\u003e    0.46587222790442795\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"units\\\": 128,\\u003cbr\\u003e    \\\"dropout_rate\\\": 0.2715982395549798,\\u003cbr\\u003e    \\\"num_layers\\\": 1,\\u003cbr\\u003e    \\\"batch_size\\\": 32,\\u003cbr\\u003e    \\\"epochs\\\": 100\\u003cbr\\u003e  },\\u003cbr\\u003e  \\\"user_attrs\\\": {\\u003cbr\\u003e    \\\"f1_score\\\": 0.46587222790442795,\\u003cbr\\u003e    \\\"precision\\\": 0.5434782608695652,\\u003cbr\\u003e    \\\"recall\\\": 0.0030120481927710845\\u003cbr\\u003e  }\\u003cbr\\u003e}\"],\"x\":[0.4322155714035034],\"y\":[0.46587222790442795],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Pareto-front Plot\"},\"xaxis\":{\"title\":{\"text\":\"loss\"}},\"yaxis\":{\"title\":{\"text\":\"F1\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('1791f6dc-5f08-4b2d-9e65-3b98dffb9e39');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Access the best hyperparameters and potentially the fine-tuned model\n",
        "optuna.visualization.plot_pareto_front(study, target_names=[\"loss\", \"F1\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFU9F8taWyb3"
      },
      "outputs": [],
      "source": [
        "#study = optuna.load_study('your_study_name.db')  # Assuming the study is saved\n",
        "\n",
        "# Get trial information\n",
        "trials = study.trials\n",
        "\n",
        "# Example: Plot validation loss of all trials\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "losses = [trial.value for trial in trials]\n",
        "plt.plot(losses)\n",
        "plt.xlabel(\"Trial\")\n",
        "plt.ylabel(\"Validation Loss\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pXipDTzfrBWG"
      },
      "outputs": [],
      "source": [
        "input_shape = (100, 8)  # 100 time steps, 10 features per step\n",
        "model = create_gru_model(input_shape, units=64, dropout_rate=0.2, output_size=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dM62WHBoKVDN"
      },
      "outputs": [],
      "source": [
        "def build_model_LSTM_AE(sequence_length, num_features, lstm_units, dropout_rate):\n",
        "    model = Sequential([\n",
        "        LSTM(lstm_units, input_shape=(sequence_length, num_features), return_sequences=True),\n",
        "        Dropout(dropout_rate),\n",
        "        LSTM(int(lstm_units / 2), return_sequences=False),\n",
        "        Dropout(dropout_rate),\n",
        "        RepeatVector(sequence_length),\n",
        "        LSTM(int(lstm_units / 2), return_sequences=True),\n",
        "        LSTM(lstm_units, return_sequences=True),\n",
        "        TimeDistributed(Dense(num_features))\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjK23T11K8g_"
      },
      "outputs": [],
      "source": [
        "lstm_units_options = [64, 128]\n",
        "dropout_options = [0.2, 0.3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUlaeUL6K6Wh"
      },
      "outputs": [],
      "source": [
        "best_loss = np.inf\n",
        "best_config = {}\n",
        "\n",
        "for units in lstm_units_options:\n",
        "    for dropout in dropout_options:\n",
        "        # Adjust your data preprocessing and sequence creation as needed\n",
        "        model = build_model(sequence_length, num_features, units, dropout)\n",
        "\n",
        "        # Assuming you have a function to prepare your data: sequences_train, sequences_val\n",
        "        history = model.fit(sequences_train, sequences_train,\n",
        "                            epochs=100,\n",
        "                            batch_size=64,  # You might also iterate over batch size options\n",
        "                            validation_data=(sequences_val, sequences_val),\n",
        "                            callbacks=[EarlyStopping(monitor='val_loss', patience=5)],\n",
        "                            verbose=0)\n",
        "\n",
        "        val_loss = min(history.history['val_loss'])\n",
        "        if val_loss < best_loss:\n",
        "            best_loss = val_loss\n",
        "            best_config = {'units': units, 'dropout': dropout}\n",
        "\n",
        "print(\"Best configuration:\", best_config)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}